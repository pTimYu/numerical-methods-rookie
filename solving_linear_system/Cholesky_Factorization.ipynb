{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e887722",
   "metadata": {},
   "source": [
    "# Cholesky Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00ef278",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Let's talk about why we need Cholesky Factorization first. Matrices can have different structures: lower triangular, upper triangular, diagonal, tridiagonal, pentadiagonal, and so on. As we showed before in LU factorization, with proper use of matrix structure, we can improve our efficiency in solving a linear system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be80403",
   "metadata": {},
   "source": [
    "## Tridiagonal Matrix\n",
    "To reinforce this point, let us consider another example: the tridiagonal matrix.\n",
    "\n",
    "A tridiagonal matrix is in this form:\n",
    "\n",
    "$$\n",
    "\\mathbf{M} = \\begin{bmatrix}\n",
    "y_1    & z_1    & 0      & \\cdots & 0      \\\\\n",
    "x_2    & y_2    & z_2    & \\ddots & \\vdots \\\\\n",
    "0      & \\ddots & \\ddots & \\ddots & 0      \\\\\n",
    "\\vdots & \\ddots & x_{n-1} & y_{n-1} & z_{n-1} \\\\\n",
    "0      & \\cdots & 0      & x_n    & y_n\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Obviously, this linear system will be easy to solve, and we can only use three vectors to store the whole stuff. To solve such system, we need to use Thomas algorithm, which only have a computational complexity of $\\mathcal{O}(n)$. Thomas algorithm is a special case of LU factorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37e80b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def thomas_algorithm(a, b, c, RHS):\n",
    "    '''\n",
    "    Thomas Algorithm for solving tridiagonal systems\n",
    "    Input:\n",
    "    Three diagonals: a, b, c\n",
    "    Right hand side: RHS\n",
    "    Output: solution x\n",
    "    '''\n",
    "    def thomas_LU(a, b, c):\n",
    "        '''\n",
    "        Thomas LU Factorization\n",
    "        Input:\n",
    "        Three diagonals: a, b, c (a is mid, b is upper side, c is lower side)\n",
    "        Output:\n",
    "        Factorized LU matrix, with stored as diagonal u1, u2, l\n",
    "        '''\n",
    "        u1 = np.array(a, dtype=float).reshape(-1)\n",
    "        u2 = np.array(b, dtype=float).reshape(-1)\n",
    "        c = np.array(c, dtype=float).reshape(-1)\n",
    "        l = np.zeros(u2.size)\n",
    "        n = u1.size\n",
    "        for i in range(n - 1):\n",
    "            l[i] = c[i] / u1[i]\n",
    "            u1[i + 1] = u1[i + 1] - l[i] * u2[i]\n",
    "\n",
    "        return u1, u2, l                \n",
    "\n",
    "    def thomas_substitution(mid, side, RHS, is_fwd=1):\n",
    "        '''\n",
    "        Forward/backward substitution that only takes two vectors\n",
    "        Input:\n",
    "        Two diagonals and RHS\n",
    "        Forward/backward selector\n",
    "        Output:\n",
    "        Solution x\n",
    "        '''\n",
    "        mid = np.array(mid, dtype=float).reshape(-1)\n",
    "        side = np.array(side, dtype=float).reshape(-1)\n",
    "        x = np.array(RHS, dtype=float).reshape(-1)\n",
    "        n = mid.size\n",
    "        if is_fwd == 1:\n",
    "            start = 1\n",
    "            end = n\n",
    "            step = 1\n",
    "            x[0] = x[0] / mid[0]\n",
    "        else:\n",
    "            start = -2\n",
    "            end = - n - 1\n",
    "            step = -1\n",
    "            x[-1] = x[-1] / mid[-1]\n",
    "        for i in range(start, end, step):\n",
    "            x[i] = x[i] - side[i - step] * x[i - step]\n",
    "            x[i] = x[i] / mid[i]\n",
    "        return x\n",
    "    \n",
    "    u1, u2, l = thomas_LU(a, b, c)\n",
    "    n = a.size\n",
    "    l_mid = np.ones(n)\n",
    "\n",
    "    y = thomas_substitution(l_mid, l, RHS)\n",
    "    x = thomas_substitution(u1, u2, y, is_fwd=0)\n",
    "\n",
    "    return x.reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaf02c4",
   "metadata": {},
   "source": [
    "Then, we solve a system with\n",
    "$$\n",
    "A = \\begin{bmatrix}\n",
    "4 & 1 & 0 & 0 \\\\\n",
    "1 & 4 & 1 & 0 \\\\\n",
    "0 & 1 & 4 & 1 \\\\\n",
    "0 & 0 & 1 & 4\n",
    "\\end{bmatrix}\\quad\n",
    "b = \\begin{bmatrix}\n",
    "6 \\\\\n",
    "12 \\\\\n",
    "18 \\\\\n",
    "19\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90568ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]]\n"
     ]
    }
   ],
   "source": [
    "sub_diag = np.array([1, 1, 1])\n",
    "main_diag = np.array([4, 4, 4, 4])\n",
    "sup_diag = np.array([1, 1, 1])\n",
    "b = np.array([6, 12, 18, 19])\n",
    "\n",
    "x = thomas_algorithm(main_diag, sup_diag, sub_diag, b)\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66150709",
   "metadata": {},
   "source": [
    "## Cholesky Factorization\n",
    "Symmetry and positive definite matrix is also a good structure for a matrix, which can be commonly seen in mechanical and electrical engineering. Symmetry matrix is easy to understand, where $\\textbf{A}=\\textbf{A}^T$. But what is a positive definite matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1270603",
   "metadata": {},
   "source": [
    "\n",
    "### Positive Definite Matrix\n",
    "Positive definite matrix is defined as:\n",
    "$$\\textbf{x}^T\\textbf{Ax}>0,\\quad\\forall\\textbf{x}\\ne\\textbf{0}\\in\\mathbb{R}^n$$\n",
    "We also have semi-definite matrix (which is a weak form):\n",
    "$$\\textbf{x}^T\\textbf{Ax}\\ge0$$\n",
    "\n",
    "> **Theorem** > If a symmetry matrix $\\textbf{A}$ has no negative or zero eigenvalues, then we can say this matrix is symmetry and positive definite.\n",
    "\n",
    "**Proof**:\n",
    "\n",
    "For the positive definite, we need to prove that $\\forall\\textbf{x}\\neq\\textbf{0}\\in\\mathbb{R}^n$, $\\textbf{x}^T\\textbf{Ax}>0$. Since this matrix is verified as a symmetric matrix, we can use the Eigendecomposition $\\textbf{A}=\\textbf{V}\\boldsymbol{\\Lambda}\\textbf{V}^T$ to show that $\\textbf{V}^T\\textbf{AV}=\\boldsymbol{\\Lambda}$. We know that eigenvectors for a full-ranked symmetry matrix should be orthonormal to each other, i.e., $\\mathbb{R}^n=\\text{span}(\\textbf{V})$. We can write them further:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\textbf{V}&=\\begin{bmatrix} \\textbf{v}_1 & \\textbf{v}_2 & \\cdots & \\textbf{v}_n \\end{bmatrix} \\\\\n",
    "\\textbf{x}&=a_1\\textbf{v}_1+a_2\\textbf{v}_2+\\cdots+a_n\\textbf{v}_n \\\\\n",
    "&=\\begin{bmatrix} \\textbf{v}_1 & \\textbf{v}_2 & \\cdots & \\textbf{v}_n \\end{bmatrix}\n",
    "\\begin{bmatrix} a_1 \\\\ a_2 \\\\ \\vdots \\\\ a_n \\end{bmatrix} \\\\\n",
    "&= \\textbf{V}\\textbf{a}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Plug this into $\\textbf{x}^T\\textbf{Ax}$ and we can get:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\textbf{x}^T\\textbf{Ax} &= (\\textbf{Va})^T\\textbf{AVa} \\\\\n",
    "&=\\textbf{a}^T\\textbf{V}^T\\textbf{AVa} \\\\\n",
    "&=\\textbf{a}^T\\boldsymbol{\\Lambda}\\textbf{a} \\\\\n",
    "&=a_1^2\\lambda_1+a_2^2\\lambda_2+\\cdots+a_n^2\\lambda_n\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Where $\\textbf{x}^T\\textbf{Ax}>0$ if and only if $\\lambda_i>0$ for arbitrary $i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ee2072",
   "metadata": {},
   "source": [
    "### Congruence Transformation\n",
    "> **Theorem** > If $A \\in \\mathbb{R}^{n \\times n}$ is symmetric positive definite and $H \\in \\mathbb{R}^{n \\times q}$ has full column rank, then $H^T AH$ is symmetric positive definite.\n",
    "\n",
    "This theorem is easy to prove, you can verify it yourself. The main problem is: why we need this theorem?\n",
    "\n",
    "Consider a quadratic system $\\textbf{E}(\\textbf{x})=\\textbf{x}^T\\textbf{Ax}$. In practice, we usually won't work with the variable $\\textbf{x}$ directly. Instead, we will have a transformation matrix applied to some variables $\\textbf{y}$, which will be written as $\\textbf{x}=\\textbf{Hy}$. Then, the transformation of the matrix becomes $\\textbf{H}^T\\textbf{AH}$.\n",
    "\n",
    "There are many other applications for Congruence Transformation, I will not list all of them here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65becb5",
   "metadata": {},
   "source": [
    "### Cholesky Factorization\n",
    "A positive definite matrix can be factorized by:\n",
    "\n",
    "$$\\textbf{A}=\\textbf{R}^T\\textbf{R}$$\n",
    "\n",
    "Where $\\textbf{R}$ is an upper triangular matrix. If $\\textbf{A}$ is a $2\\times 2$ matrix, we can easily get the factorization analytically by setting and solving parameters for $\\textbf{R}$ and $\\textbf{A}$:\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\begin{bmatrix}\n",
    "a & b \\\\\n",
    "b & c\n",
    "\\end{bmatrix}, \\quad\n",
    "\\mathbf{R} = \\begin{bmatrix}\n",
    "\\sqrt{a} & u \\\\\n",
    "0 & v\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Where $u = \\frac{b}{\\sqrt{a}}$ and $v = \\sqrt{c - u^2}$.\n",
    "\n",
    "Now, let's consider the general case here ($n\\times n$).\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\left[ \n",
    "\\begin{array}{c|c}\n",
    "a_1 & \\mathbf{b}_1^\\top \\\\\n",
    "\\hline\n",
    "\\mathbf{b}_1 & \\mathbf{C}_1\n",
    "\\end{array} \n",
    "\\right]\n",
    "$$\n",
    "\n",
    "Now set the relationship between $\\textbf{R}$ and $\\textbf{A}$:\n",
    "\n",
    "$$\n",
    "\\underbrace{\n",
    "\\left[ \\begin{array}{c|c}\n",
    "\\sqrt{a_1} & \\mathbf{0} \\\\\n",
    "\\hline\n",
    "\\mathbf{u}_1 & \\mathbf{V}_1^\\top\n",
    "\\end{array} \\right]\n",
    "}_{\\mathbf{R}_1^\\top}\n",
    "\\underbrace{\n",
    "\\left[ \\begin{array}{c|c}\n",
    "\\sqrt{a_1} & \\mathbf{u}_1^\\top \\\\\n",
    "\\hline\n",
    "\\mathbf{0} & \\mathbf{V}_1\n",
    "\\end{array} \\right]\n",
    "}_{\\mathbf{R}_1}\n",
    "=\n",
    "\\left[ \\begin{array}{c|c}\n",
    "a_1 & \\mathbf{b}_1^\\top \\\\\n",
    "\\hline\n",
    "\\mathbf{b}_1 & \\mathbf{V}_1^\\top \\mathbf{V}_1 + \\mathbf{u}_1 \\mathbf{u}_1^\\top\n",
    "\\end{array} \\right]\n",
    "=\n",
    "\\left[ \\begin{array}{c|c}\n",
    "a_1 & \\mathbf{b}_1^\\top \\\\\n",
    "\\hline\n",
    "\\mathbf{b}_1 & \\mathbf{C}_1\n",
    "\\end{array} \\right]\n",
    "= \\mathbf{A}\n",
    "$$\n",
    "\n",
    "Where $\\textbf{u}_1=\\frac{\\textbf{b}_1}{\\sqrt{a_1}}$ and $\\textbf{A}_1=\\mathbf{V}_1^\\top \\mathbf{V}_1=\\textbf{C}_1-\\mathbf{u}_1 \\mathbf{u}_1^\\top$.\n",
    "\n",
    "$\\textbf{A}_1=\\mathbf{V}_1^\\top \\mathbf{V}_1$ can be considered as a sub-factorization. By repeating this step until $\\textbf{A}_{n-1}$ is a $2\\times 2$ matrix ($2\\times 2$ matrix can be factorized, as mentioned before)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "086bf811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cholesky_factorization(A):\n",
    "    '''\n",
    "    Cholesky Factorization\n",
    "    Input:\n",
    "    Symmetry and positive definite matrix A\n",
    "    Output:\n",
    "    Factorized upper triangular matrix R\n",
    "    '''\n",
    "    A = np.array(A, dtype=float)\n",
    "    n = A.shape[0]\n",
    "    for i in range(n):\n",
    "        A[i, i] = np.sqrt(A[i, i])\n",
    "        A[i, i + 1:] = A[i, i + 1:] / A[i, i]\n",
    "        for j in range(i + 1, n):\n",
    "            for k in range(i + 1, n):\n",
    "                A[j, k] = A[j, k] - A[i, j] * A[i, k]\n",
    "    R = np.triu(A, k=0)\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b268ff9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factorized matrix R:\n",
      "[[ 2.  6. -8.]\n",
      " [ 0.  1.  5.]\n",
      " [ 0.  0.  3.]]\n",
      "Did the decomposition process succeed? True\n"
     ]
    }
   ],
   "source": [
    "A = np.array([\n",
    "    [4, 12, -16],\n",
    "    [12, 37, -43],\n",
    "    [-16, -43, 98]])\n",
    "\n",
    "R = cholesky_factorization(A)\n",
    "print(\"Factorized matrix R:\")\n",
    "print(R)\n",
    "print(f\"Did the decomposition process succeed? {(R.T @ R == A).all()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fab8252",
   "metadata": {},
   "source": [
    "### Symmetric Indefinite Systems\n",
    "If $\\textbf{A}$ is a symmetric indefinite system, Cholesky Factorization is not applicable. The LDL factorization is used, where\n",
    "$$\\textbf{PAP}^T=\\textbf{LDL}^T$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f530cb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for LDL factorization (Not completed yet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc56d844",
   "metadata": {},
   "source": [
    "### Summary Table\n",
    "<center>\n",
    "\n",
    "| Matrix structure | Solver | Cost |\n",
    "| :--- | :--- | :--- |\n",
    "| Tridiagonal | Thomas algorithm | $\\mathcal{O}(n)$ |\n",
    "| Symmetric and positive definite (SPD) | Cholesky | $\\mathcal{O}(n^3/3)$ |\n",
    "| General dense | LU with pivoting | $\\mathcal{O}(n^3)$ |\n",
    "\n",
    "</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
