{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23eaac2f",
   "metadata": {},
   "source": [
    "# Gaussian Elimination and LU Decomposition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3eb783f",
   "metadata": {},
   "source": [
    "## Forward and Backward Substitution\n",
    "Still start from the linear system\n",
    "\n",
    "$$\\textbf{Ax}=\\textbf{b}$$\n",
    "\n",
    "How can we use our computer to solve for it?\n",
    "\n",
    "First, let's consider some matrix with the structure of upper triangular matrix and lower triangular matrix:\n",
    "\n",
    "$$\n",
    "U = \\begin{bmatrix}\n",
    "a_{11} & a_{12} & \\cdots & a_{1n} \\\\\n",
    "0      & a_{22} & \\cdots & a_{2n} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "0      & 0      & \\cdots & a_{nn}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "L = \\begin{bmatrix}\n",
    "a_{11} & 0      & \\cdots & 0      \\\\\n",
    "a_{21} & a_{22} & \\cdots & 0      \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "a_{n1} & a_{n2} & \\cdots & a_{nn}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "This seems to be easy to solve, we can do that by using backward and forward substitution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "39abb3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def forward_substitution(A, b):\n",
    "    '''\n",
    "    Forward Substitution\n",
    "    Input: Lower triangular, full-ranked, squared matrix A, and the RHS b\n",
    "    Output: Solution to this system x\n",
    "    '''\n",
    "    # Initialize and copy the identity\n",
    "    A = np.array(A, dtype=float)\n",
    "    b = np.array(b, dtype=float).reshape(-1)\n",
    "    n = A.shape[0]\n",
    "    m = A.shape[1]\n",
    "    x = np.zeros(n)\n",
    "\n",
    "    # Check if it is lower triangular, full-ranked, squared\n",
    "    A_lower_tri = np.tril(A, k=0)\n",
    "    if not(np.equal(A, A_lower_tri).all()) or (np.diag(A) == 0).all() or m != n:\n",
    "        raise ValueError(\"The input matrix is not a lower triangular, full-ranked, squared matrix.\")\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(i):\n",
    "            b[i] = b[i] - A[i, j] * x[j]\n",
    "        x[i] = b[i] / A[i, i]\n",
    "        \n",
    "    return x.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d09c2ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5]\n",
      " [ 0.5]\n",
      " [-1. ]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[2, 0, 0],\n",
    "              [3, 1, 0],\n",
    "              [6, 4, 2]])\n",
    "\n",
    "b = np.array([1, 2, 3])\n",
    "\n",
    "print(forward_substitution(A, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444e3b88",
   "metadata": {},
   "source": [
    "The algorithm of the backward substitution is quite similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "753d6f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_substitution(A, b):\n",
    "    '''\n",
    "    Backward Substitution\n",
    "    Input: Upper triangular, full-ranked, squared matrix A, and the RHS b\n",
    "    Output: Solution to this system x\n",
    "    '''\n",
    "    # Initialize and copy the identity\n",
    "    A = np.array(A, dtype=float)\n",
    "    b = np.array(b, dtype=float).reshape(-1)\n",
    "    n = A.shape[0]\n",
    "    m = A.shape[1]\n",
    "    x = np.zeros(n)\n",
    "\n",
    "    # Check if it is upper triangular, full-ranked, squared\n",
    "    A_upper_tri = np.triu(A, k=0)\n",
    "    if not(np.equal(A, A_upper_tri).all()) or (np.diag(A) == 0).all() or m != n:\n",
    "        raise ValueError(\"The input matrix is not an upper triangular, full-ranked, squared matrix.\")\n",
    "    \n",
    "    for i in range(n, 0, -1):\n",
    "        i = i - 1\n",
    "        for j in range(n - 1, i, -1):\n",
    "            b[i] = b[i] - A[i, j] * x[j]\n",
    "        x[i] = b[i] / A[i, i]\n",
    "\n",
    "    return x.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d03e09f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9]\n",
      " [1. ]\n",
      " [1. ]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([\n",
    "    [10, 2,  3],\n",
    "    [0,  5,  6],\n",
    "    [0,  0,  1]])\n",
    "\n",
    "b = np.array([14, 11, 1])\n",
    "\n",
    "print(backward_substitution(A, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07ff75f",
   "metadata": {},
   "source": [
    "## Gaussian Elimination\n",
    "As shown before, it is easy to solve an upper or lower triangular matrix. Hence, we are seeking for a method to convert our linear system to such structure. Here, we introduced Gaussian Elimination. By doing multiple operations, we can convert a matrix to the upper triangular matrix. The opeation can be expressed by the matrix multiplication:\n",
    "\n",
    "$$\\textbf{U}=\\textbf{M}_n\\textbf{M}_{n-1}\\cdots\\textbf{M}_2\\textbf{M}_1\\textbf{A}$$\n",
    "\n",
    "Where $\\textbf{M}_i$ is some operations to the system. In Gaussian Elimination, we will have three types of operations: Permutation, Scaling, Elimination. We denote them as $\\textbf{P}$, $\\textbf{S}$ and $\\textbf{E}$. We do the permutation for partial pivoting to avoid some small pivot numbers, and the reason for scaling is similar. Note that $\\textbf{P}^{-1}=\\textbf{P}^{T}$ and $\\textbf{S}=\\textbf{S}^{T}$ ($\\textbf{S}$ is the diagonalized matrix). These two operations are all for **numerical stability**, which you will see later. But for now, let's talk about the elimination operation.\n",
    "\n",
    "Every elimination operation can be expressed as a lower-triangular matrix where:\n",
    "\n",
    "$$\\textbf{E}_{ij}=\\textbf{I}+c_{ij}\\textbf{i}_i\\textbf{i}_j^T,\\quad i>j$$\n",
    "\n",
    "$\\textbf{E}_{ij}$ means we do row operation on row $i$ based on row $j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b772e181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_elimination(A, b):\n",
    "    '''\n",
    "    Gaussian Elimination\n",
    "    Input: Full-ranked and squared matrix A, RHS: b\n",
    "    Output: Solution x\n",
    "    '''\n",
    "    # Initialize and copy the identity\n",
    "    A = np.array(A, dtype=float)\n",
    "    b = np.array(b, dtype=float).reshape(-1)\n",
    "    n = A.shape[0]\n",
    "    m = A.shape[1]\n",
    "    x = np.zeros(n)\n",
    "\n",
    "    # Make sure to input squared matrix\n",
    "    if m != n:\n",
    "        raise ValueError(\"The input matrix is not a squared matrix.\")\n",
    "    \n",
    "    for i in range(n):\n",
    "        # Partial pivoting\n",
    "        # It can be shown that partial pivoting will not affect the order of x\n",
    "        idx = i + np.argmax(np.abs(A[i:, i]))\n",
    "        if idx != i:\n",
    "            # A\n",
    "            row_temp = A[i, :].copy()\n",
    "            A[i, :] = A[idx, :]\n",
    "            A[idx, :] = row_temp\n",
    "            # RHS\n",
    "            b_temp = b[i].copy()\n",
    "            b[i] = b[idx]\n",
    "            b[idx] = b_temp\n",
    "\n",
    "        for j in range(i + 1, n):\n",
    "            num = A[j, i] / A[i, i]\n",
    "            for k in range(i, n):\n",
    "                A[j, k] = A[j, k] - A[i, k] * num\n",
    "            b[j] = b[j] - b[i] * num\n",
    "\n",
    "    x = backward_substitution(A, b)\n",
    "    return x.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1ddaa430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.]\n",
      " [-2.]\n",
      " [ 3.]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([\n",
    "    [2.0,  1.0, -1.0],\n",
    "    [-3.0, -1.0,  2.0],\n",
    "    [-2.0,  1.0,  2.0]])\n",
    "\n",
    "b = np.array([-3.0, 5.0, 2.0])\n",
    "\n",
    "print(gaussian_elimination(A, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c906962",
   "metadata": {},
   "source": [
    "## LU Decomposition\n",
    "Recall the equation of Gaussian Elimination:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\textbf{U} &= \\textbf{M}_n\\textbf{M}_{n-1}\\cdots\\textbf{M}_2\\textbf{M}_1\\textbf{A} \\\\\n",
    "&= \\textbf{E}_m\\textbf{E}_{m-1}\\cdots\\textbf{E}_2\\textbf{E}_1\\textbf{P}\\textbf{S}\\textbf{A}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "By doing some inversion, we can revert the upper-triangular matrix to the origin. For the scaling matrix $\\textbf{S}$, since it is an diagonalized matrix, we do not need to pay much attention to it. For the permutation matrix $\\textbf{P}$, We can just leave it with the original matrix $\\textbf{A}$. Hence, the only thing we need to do is to inverse the elimination matrix $\\textbf{E}$.\n",
    "\n",
    "Since\n",
    "\n",
    "$$\\textbf{E}_{ij}=\\textbf{I}+c_{ij}\\textbf{i}_i\\textbf{i}_j^T,\\quad i>j$$\n",
    "\n",
    "We can have its inverse\n",
    "\n",
    "$$\\textbf{E}_{ij}^{-1}=\\textbf{I}-c_{ij}\\textbf{i}_i\\textbf{i}_j^T,\\quad i>j$$\n",
    "\n",
    "Note that $\\textbf{E}_{ij}^{-1}$ is also lower-triangular matrix.\n",
    "\n",
    "Then, we will find that\n",
    "\n",
    "$$\\underbrace{\\textbf{E}^{-1}_{m}\\textbf{E}^{-1}_{m-1}\\cdots\\textbf{E}^{-1}_{2}\\textbf{E}^{-1}_{1}}_\\textbf{L}\\underbrace{\\textbf{E}_m\\textbf{E}_{m-1}\\cdots\\textbf{E}_2\\textbf{E}_1\\textbf{P}\\textbf{S}\\textbf{A}}_\\textbf{U}=\\textbf{PSA}$$\n",
    "\n",
    "It is easy to figure out that the multiplication of lower-triangular matrices is also a lower-triangular matrix, then we got our LU factorization (Here, we choose to ignore $\\textbf{S}$ for a better demostration.):\n",
    "\n",
    "$$\\textbf{LU}=\\textbf{PA}$$\n",
    "\n",
    "The most important thing is to understand **why we need LU Facorization**. By factorize $\\textbf{A}$ to $\\textbf{LU}$, we can reuse it in the future even if the RHS, $\\textbf{b}$ is different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a70559e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LU_decomposition(A):\n",
    "    '''\n",
    "    LU Decompostion\n",
    "    Input:\n",
    "    Full-ranked and squared matrix A\n",
    "    Output:\n",
    "    Decomposed lower and upper triangular matrix L and U\n",
    "    Pivoting index vector p\n",
    "    '''\n",
    "    # Initialize and copy the identity\n",
    "    U = np.array(A, dtype=float)\n",
    "    n = U.shape[0]\n",
    "    m = U.shape[1]\n",
    "    L = np.eye(n)\n",
    "    p = np.arange(n)\n",
    "\n",
    "    # Make sure to input squared matrix\n",
    "    if m != n:\n",
    "        raise ValueError(\"The input matrix is not a squared matrix.\")\n",
    "    \n",
    "    for i in range(n):\n",
    "        # Partial pivoting\n",
    "        # It can be shown that partial pivoting will not affect the order of x\n",
    "        idx = i + np.argmax(np.abs(U[i:, i]))\n",
    "        if idx != i:\n",
    "            # U\n",
    "            row_temp_U = U[i, :].copy()\n",
    "            U[i, :] = U[idx, :]\n",
    "            U[idx, :] = row_temp_U\n",
    "            # L\n",
    "            row_temp_L = L[i, :i].copy()\n",
    "            L[i, :i] = L[idx, :i]\n",
    "            L[idx, :i] = row_temp_L\n",
    "            # p\n",
    "            p[i], p[idx] = p[idx], p[i]\n",
    "            \n",
    "        # Here, we use a same algorithm as the Gaussian Elimination for U\n",
    "        for j in range(i + 1, n):\n",
    "            L[j, i] = U[j, i] / U[i, i]\n",
    "            for k in range(i, n):\n",
    "                U[j, k] = U[j, k] - L[j, i] * U[i, k]\n",
    "    \n",
    "    return L, U, p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cd04e4",
   "metadata": {},
   "source": [
    "After performing the LU factorization, we can solve this system by using a forward substitution and a backward substitution:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\textbf{PAx} &= \\textbf{Pb} \\\\\n",
    "\\textbf{LUx} &= \\textbf{Pb} \\\\\n",
    "\\end{align*}\n",
    "\\implies \n",
    "\\begin{cases}\n",
    "\\textbf{Ly}=\\textbf{Pb} \\\\\n",
    "\\textbf{Ux}=\\textbf{y}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Doing a forward and backward substitution will cost much less than doing a gaussian elimination or something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "71b91747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lower triangular matrix:\n",
      "[[ 1.          0.          0.        ]\n",
      " [ 0.66666667  1.          0.        ]\n",
      " [-0.66666667  0.2         1.        ]]\n",
      "Upper triangular matrix:\n",
      "[[-3.         -1.          2.        ]\n",
      " [ 0.          1.66666667  0.66666667]\n",
      " [ 0.          0.          0.2       ]]\n",
      "Solution:\n",
      "[[ 1.]\n",
      " [-2.]\n",
      " [ 3.]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([\n",
    "    [2.0,  1.0, -1.0],\n",
    "    [-3.0, -1.0,  2.0],\n",
    "    [-2.0,  1.0,  2.0]])\n",
    "\n",
    "b = np.array([-3.0, 5.0, 2.0])\n",
    "\n",
    "L, U, p = LU_decomposition(A)\n",
    "\n",
    "print(\"Lower triangular matrix:\")\n",
    "print(L)\n",
    "print(\"Upper triangular matrix:\")\n",
    "print(U)\n",
    "\n",
    "y = forward_substitution(L, b[p])\n",
    "x = backward_substitution(U, y)\n",
    "\n",
    "print(\"Solution:\")\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dd5ca3",
   "metadata": {},
   "source": [
    "## Gaussian-Jordan Elimination\n",
    "*Will do this later, since didn't teach in MECH309*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b181cf",
   "metadata": {},
   "source": [
    "## Summary of these Algorithms\n",
    "\n",
    "| Algorithm | Leading Term (FLOPs) | Big-O Complexity | Best Use Case |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **Forward / Backward Substitution** | $n^2$ | $O(n^2)$ | Solving triangular systems (after LU or QR). |\n",
    "| **Gaussian Elimination** | $\\frac{2}{3}n^3$ | $O(n^3)$ | General purpose solving for a single vector $b$. |\n",
    "| **LU Factorization** | $\\frac{2}{3}n^3$ | $O(n^3)$ | Efficient when solving $Ax = b$ for many different $b$ vectors. |\n",
    "| **Gauss-Jordan Elimination** | $n^3$ | $O(n^3)$ | Finding the matrix inverse (rarely recommended for solving systems). |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
